{"cells":[{"cell_type":"markdown","metadata":{"id":"kQCoNsOJimlP"},"source":["Training"]},{"cell_type":"code","source":["!pip install albumentations==1.3.0\n","!pip install -I opencv-python-headless==4.1.2.30"],"metadata":{"id":"f8w8xmLVQKDH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tyU7JTsaJRRc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670200392186,"user_tz":-120,"elapsed":30675,"user":{"displayName":"Juho Holopainen","userId":"05552757142261760684"}},"outputId":"da61b42b-f290-44a4-d1ff-fa27ea52317c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBJKWuhChsXQ"},"outputs":[],"source":["import math\n","import os\n","import cv2\n","import numpy as np\n","import tempfile\n","import threading\n","import pandas\n","from itertools import cycle\n","from imutils.paths import list_images\n","import albumentations as A\n","from tqdm.auto import tqdm\n","\n","from matplotlib import pyplot as plt\n","from matplotlib.ticker import AutoMinorLocator\n","\n","import tensorflow as tf\n","from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import *\n","from tensorflow.keras.optimizers import *\n","from tensorflow.keras.losses import binary_crossentropy\n","from tensorflow import math\n","from tensorflow.keras import backend as K"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xd5D06Jgeyj9"},"outputs":[],"source":["def center_crop(path):\n","    images = list(list_images(path))\n","\n","    for filename in tqdm(images):\n","        original = cv2.imread(filename)\n","\n","        # Center crop image from size 218*178 to 160*160\n","        y, x = original.shape[:2]\n","        yo, xo = (y - 160) // 2, (x - 160) // 2\n","        cropped = original[yo:yo + 160, xo:xo + 160]\n","        cropped = cv2.resize(cropped, (160, 160))\n","        cv2.imwrite(filename, cropped)\n","\n","if not os.path.isfile(\"/content/drive/MyDrive/celeba/cropped_images.zip\"):\n","  !unzip -qq /content/drive/MyDrive/celeba/img_align_celeba.zip\n","  center_crop(\"img_align_celeba\")\n","  !zip -r /content/drive/MyDrive/celeba/cropped_images.zip img_align_celeba\n","\n","else:\n","  !unzip -qq /content/drive/MyDrive/celeba/cropped_images.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AUQfKN-fhyjE"},"outputs":[],"source":["def euclidean(p):\n","    euclidean_2d = tf.reduce_sum(tf.square(p - p[:, None]), axis=-1) / 2.0\n","    return euclidean_2d\n","\n","def loss(t, p):\n","    # unpack euclidean matrix\n","    euclidean_2d = euclidean(p)\n","    # set positives > 1 not to include them in min negatives\n","    neg = tf.reduce_min(euclidean_2d + t, axis=-1)\n","    # clip negative to avoid sparsing\n","    neg = tf.minimum(neg, 0.5) / 0.5\n","    # positive distances\n","    pos = tf.reshape(tf.boolean_mask(euclidean_2d, t == 1), [-1])\n","    # make labels\n","    pos_lbls, neg_lbls = tf.zeros_like(pos), tf.ones_like(neg)\n","    # take binary crossentropy\n","    return binary_crossentropy([pos_lbls, neg_lbls], [pos, neg])\n","\n","def mean_pos(t, p):\n","    # unpack euclidean matrix\n","    euclidean_2d = euclidean(p)\n","    # get average of positive distances\n","    return tf.reduce_mean(tf.boolean_mask(euclidean_2d, t == 1))\n","\n","def mean_neg(t, p):\n","    # unpack euclidean matrix\n","    euclidean_2d = euclidean(p)\n","    # get average of negative distances\n","    return tf.reduce_mean(tf.boolean_mask(euclidean_2d, t == 0))\n","\n","def accuracy(t, p):\n","    # unpack euclidean matrix\n","    euclidean_2d = euclidean(p)\n","    temp = euclidean_2d + tf.cast(t == 2, p.dtype)\n","    # average of rows where positive distance is the smallest value\n","    acc = tf.equal(tf.argmin(temp, axis=-1), tf.argmax(t == 1, axis=-1)),\n","    return tf.reduce_mean(tf.cast(acc, p.dtype))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n5BOoV4LAXu1"},"outputs":[],"source":["class ImageGen:\n","\n","    def __init__(self, batch_size, path, identites, subset=\"train\"):\n","        self.path = path\n","        self.subset = subset\n","        self.bs = batch_size\n","\n","        self.lock = threading.Lock()\n","        self.data = self.unpack_data(identites, path)\n","        self.rand_gen = self.get_rand_generator()\n","        self.it = self.get_iterator()\n","\n","    def unpack_data(self, identities_path, unzip_path):\n","        # read identity_CelebA\n","        df = pandas.read_csv(identities_path)\n","\n","        # get filenames for each identity except bad images labelled as \"0\"\n","        df = df.loc[df['identity'] != 0]\n","\n","        # get unique classes\n","        unique = np.unique(df[\"identity\"])\n","\n","        # make dictionary of identities and related images\n","        identity_dict = {}\n","\n","        identities = df['identity'].values\n","        for class_name in tqdm(unique):\n","            filenames = df[np.in1d(identities, [class_name])][\"filename\"]\n","            imgs = list(map(lambda x: os.path.join(unzip_path, x), filenames))\n","\n","            # train images\n","            if self.subset == \"train\" and len(filenames) >= 2:\n","                combs = self.chunker(imgs, 2)\n","                identity_dict[class_name] = combs\n","\n","            # test images\n","            if self.subset != \"train\" and len(filenames) == 1:\n","                identity_dict[class_name] = cycle([[imgs[0], imgs[0]]])\n","\n","        return identity_dict\n","\n","    @staticmethod\n","    def get_rand_generator():\n","        transform = A.Compose([\n","            A.HorizontalFlip(p=0.5),\n","            A.GaussNoise(p=0.5),\n","            A.HueSaturationValue(hue_shift_limit=20,\n","                                 sat_shift_limit=30,\n","                                 val_shift_limit=20,\n","                                 p=0.5),\n","            A.ShiftScaleRotate(rotate_limit=15,\n","                               scale_limit=(-0.16, 0.16),\n","                               shift_limit=0.15,\n","                               border_mode=cv2.BORDER_CONSTANT,\n","                               p=1.0),\n","            A.RandomBrightnessContrast(brightness_limit=0.25, p=1.0)\n","        ])\n","        return transform\n","\n","    def get_image(self, path):\n","        img = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n","        img = self.rand_gen(image=img)[\"image\"]\n","        return np.expand_dims(img, axis=0)\n","\n","    def create_static_label(self):\n","        y = np.tile(np.arange(self.bs), 2)\n","        y = np.equal(y, y[:, None]).astype(float)\n","        y[np.diag_indices(self.bs * 2)] = 2\n","        return y\n","\n","    def get_iterator(self):\n","\n","        # data chunker for sampling classes\n","        chunker = self.chunker(list(self.data.keys()), self.bs)\n","\n","        # holders for batch data\n","        x = np.zeros((self.bs * 2, 160, 160, 3), dtype=np.float32)\n","        y = self.create_static_label()\n","\n","        for batch in chunker:\n","            \n","            # (class1_img1, class1_img2), (class2_img1, class2_img2)...\n","            all_paths = [next(self.data[cls]) for cls in batch]\n","            \n","            for index, (path1, path2) in enumerate(all_paths):\n","                x[index] = self.get_image(path1)\n","                x[index + self.bs] = self.get_image(path2)\n","\n","            x = preprocess_input(x)\n","            yield x, y\n","\n","    @staticmethod\n","    def chunker(lst, bs):\n","        while True:\n","            np.random.shuffle(lst)\n","            for _ in np.arange(np.ceil(len(lst) / bs)):\n","                lst = np.roll(lst, bs)\n","                yield lst[:bs]\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        with self.lock:\n","            return next(self.it)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCRk_PzWwqH9"},"outputs":[],"source":["def plot_history(csv_path, save_path):\n","    contents = pandas.read_csv(csv_path)\n","    epochs = np.arange(len(contents))\n","    train_keys = [i for i in contents.keys() if \"val\" not in i]\n","    train_keys.remove(\"epoch\")\n","\n","    for key in train_keys:\n","        train = contents[key]\n","        val = contents[\"val_\" + key]\n","        y_max = np.maximum(train.max(), val.max())\n","        y_max = np.maximum(y_max, 1.1)\n","\n","        fig, ax = plt.subplots()\n","        ax.grid(which='minor', alpha=0.2)\n","        ax.grid(which='major', alpha=0.5)\n","\n","        # tics x-axis\n","        step = len(epochs) // 10\n","        ax.set_xticks(np.arange(0.0, len(epochs) + 1, step), minor=False)\n","        ax.xaxis.set_minor_locator(AutoMinorLocator(5))\n","\n","        # tics y-axis\n","        step = 0.1 if y_max <= 1.1 else 0.2\n","        ax.set_yticks(np.arange(0, y_max, step), minor=False,)\n","        ax.yaxis.set_minor_locator(AutoMinorLocator(5))\n","        plt.ylim(0, y_max)\n","\n","        ax.plot(epochs, train, color='g')\n","        ax.plot(epochs, val, color='b')\n","\n","        plt.title('model {}'.format(key))\n","        plt.ylabel(key)\n","        plt.xlabel('epoch')\n","        plt.legend(['train', 'test'], loc='upper left')\n","        plt.savefig(\"{}/{}.png\".format(save_path, key))\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qdx1Aw_-RYOH"},"outputs":[],"source":["def get_model_v2(weights=None, size=256, alpha=1.0):\n","    model = MobileNetV2(input_shape=(160, 160, 3),\n","                        alpha=alpha,\n","                        include_top=False,\n","                        pooling=\"max\")\n","    \n","    x = Dense(size, activation=\"relu\")(model.layers[-1].output)\n","    x = Lambda(lambda d: tf.math.l2_normalize(d, axis=1), name=\"l2-norm\")(x)\n","\n","    model = Model(inputs=[model.input], outputs=[x])\n","\n","    if weights:\n","        model.load_weights(weights, by_name=True, skip_mismatch=True)\n","\n","    return model   "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tnamv1tkbVa_"},"outputs":[],"source":["# data paths\n","identities = r\"/content/drive/My Drive/celeba/updated_identities.csv\"\n","unzip_path = r\"img_align_celeba\"\n","\n","bs_train = 100\n","bs_val = 100\n","\n","tr_gen = ImageGen(bs_train, unzip_path, identities, subset=\"train\")\n","val_gen = ImageGen(bs_val, unzip_path, identities, subset=\"test\")\n","\n","print(\"train has {} classes and validation has {} classes\".format(len(tr_gen), len(val_gen)))"]},{"cell_type":"markdown","source":["Save a sample batch as an image"],"metadata":{"id":"FHzW7OUjGwEG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"jMUHn1d2NSow"},"outputs":[],"source":["def save_sample(x):\n","    x1 = np.vstack([(i+1) * 127.5 for i in x[:len(x) // 2]]).astype(np.uint8)\n","    x2 = np.vstack([(i+1) * 127.5 for i in x[len(x) // 2:]]).astype(np.uint8)\n","    cv2.imwrite(\"test.png\", cv2.cvtColor(np.hstack([x1, x2]), cv2.COLOR_BGR2RGB))\n","\n","x, y = next(tr_gen)\n","save_sample(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZvxkPcln3iI"},"outputs":[],"source":["K.clear_session()\n","\n","warmed_model = None\n","warmed_model = r\"\"\n","model = get_model_v2(warmed_model, 256, alpha=0.75)\n","\n","model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0LzmCcDgc2r"},"outputs":[],"source":["epochs = 750\n","optimizer = Adam(learning_rate=0.001)\n","save_path =  r\"/content/drive/MyDrive/\"\n","\n","mcp = tf.keras.callbacks.ModelCheckpoint(\n","    filepath= r\"%s/{epoch:02d}_{val_loss:.3f}.h5\" % save_path,\n","    monitor=\"val_loss\",\n","    verbose=1,\n","    save_best_only=True,\n","    mode=\"auto\")\n","\n","csv_log = tf.keras.callbacks.CSVLogger(\n","    filename=r\"%s/history.csv\" % save_path,\n","    separator=\",\",\n","    append=True)\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=[mean_pos, mean_neg, accuracy])\n","history = model.fit(x=tr_gen,\n","                    steps_per_epoch=int(np.ceil(len(tr_gen) / bs_train)),\n","                    validation_data=val_gen,\n","                    validation_steps=int(np.ceil(len(val_gen) / bs_val)),\n","                    epochs=epochs, callbacks=[mcp, csv_log])\n","\n","plot_history(history, save_path)\n","model.save(os.path.join(save_path, \"final_model.h5\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kgUpEA84VZDo"},"outputs":[],"source":["plot_history(r\"%s/history.csv\" % save_path, save_path)\n","model.save(os.path.join(save_path, \"final_model_2.h5\"))"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}